# Hugging Face ì†Œê°œ ë° í™œìš© ê°€ì´ë“œ

Hugging FaceëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸, ë°ì´í„°ì…‹, ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê³µìœ í•˜ê³  ë°°í¬í•˜ê¸° ìœ„í•œ í”Œë«í¼ìœ¼ë¡œ, LLM ì´í›„ í‘œì¤€ìœ¼ë¡œ ìë¦¬ ì¡ì•˜ìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” Hugging Face ìƒíƒœê³„ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œì™€ ì´ë¥¼ ì‹¤ë¬´ì—ì„œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

| ğŸ’¡ í•„ìì˜ ì˜ê²¬ |
|---------|
| í—ˆê¹…í˜ì´ìŠ¤ê°€ ì‚¬ì‹¤ìƒ AI ìª½ì—ì„œëŠ” githubê³¼ ê°™ì€ ìœ„ìƒì´ì£ . ì¤‘êµ­ ìª½ì—ëŠ” ModelScope ì´ë¼ëŠ” ëŒ€ì²´ì œ(?) ê°€ ìˆê¸´ í•©ë‹ˆë‹¤, ë”¥ëŸ¬ë‹ ì‹œëŒ€ë¥¼ ë³´ë©´, tfhub ì´ë‚˜ kaggle ë„ ìˆì—ˆì§€ë§Œ, Transformer ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ ëª¨ë¸ë“¤ì´ ì²œí•˜í†µì¼ì„ í•˜ê³  ê·¸ ëª¨ë¸ë“¤ì— ë§ì´ ì‚¬ìš©ë˜ëŠ” í—ˆê¹…í˜ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë•ë¶„ì¸ì§€, í—ˆê¹…í˜ì´ìŠ¤ê°€ ì‚¬ì‹¤ìƒ í‘œì¤€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. |


## Hugging Face í”Œë«í¼ ê°œìš”

### ëª¨ë¸ ë° ë°ì´í„°ì…‹ ì €ì¥ì†Œ

Hugging Face Models Hubì€ 1,000,000ê°œ ì´ìƒì˜ ëª¨ë¸ê³¼ 200,000ê°œ ì´ìƒì˜ ë°ì´í„°ì…‹ì„ í˜¸ìŠ¤íŒ…í•©ë‹ˆë‹¤. ê° ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì€ í”Œë«í¼ ë‚´ Git ì €ì¥ì†Œì— ìˆì–´ ë²„ì „ ê´€ë¦¬, ì»¤ë°‹ ê¸°ë¡, ì´ìŠˆ/í† ë¡  ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

- ëª¨ë¸ ì—…ë¡œë“œ: ì›¹ UIë‚˜ Git, huggingface_hub Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ëª¨ë¸ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Transformersë¡œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•œ í›„ model.push_to_hub("username/my-model")ì„ ì‹¤í–‰í•˜ë©´ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ì†Œì— ì»¤ë°‹ë©ë‹ˆë‹¤. ëª¨ë¸ì€ ê³µê°œ ë˜ëŠ” ë¹„ê³µê°œë¡œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.

```python
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (ë˜ëŠ” ìì²´ í•™ìŠµí•œ ëª¨ë¸ ì‚¬ìš©)
model = AutoModelForSequenceClassification.from_pretrained("llama...")
tokenizer = AutoTokenizer.from_pretrained("llama...")

# Hubì— ëª¨ë¸ ì—…ë¡œë“œ (ë¡œê·¸ì¸ í•„ìš”)
model.push_to_hub("username/my_llama...")
tokenizer.push_to_hub("username/my_llama")
```

- ë°ì´í„°ì…‹ ì—…ë¡œë“œ : ë°ì´í„°ì…‹ë„ ìœ ì‚¬í•˜ê²Œ ë°ì´í„° ì €ì¥ì†Œë¡œ ì €ì¥ë©ë‹ˆë‹¤. ìƒˆ ë°ì´í„°ì…‹ ì €ì¥ì†Œë¥¼ ë§Œë“¤ê³  íŒŒì¼(CSV, JSONL, ì´ë¯¸ì§€ ë“±)ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œëŠ” ë“œë˜ê·¸ ì•¤ ë“œë¡­ ì—…ë¡œë“œë¥¼ ì§€ì›í•˜ë©°, ê° ë°ì´í„°ì…‹ ì €ì¥ì†Œì—ëŠ” ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ ìŠ¤í¬ë¦½íŠ¸ë‚˜ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
# ë°ì´í„°ì…‹ì„ Hugging Face Hubì— ì—…ë¡œë“œí•˜ëŠ” ì˜ˆì‹œ
from datasets import Dataset
import pandas as pd

# ë¡œì»¬ CSV íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ ìƒì„±
df = pd.read_csv("my_data.csv")
dataset = Dataset.from_pandas(df)

# Hubì— ë°ì´í„°ì…‹ ì—…ë¡œë“œ
dataset.push_to_hub("username/my-dataset")
```

- ëª¨ë¸ / ë°ì´í„°ì…‹ ì‚¬ìš© : ìœ„ì˜ ì—…ë¡œë“œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë‹¤ìš´ë°›ì•„ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ ë‹¹ì—°íˆ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ìŒ ì‹¤ìŠµ ë¬¸ì„œì—ì„œ ì´ì–´ì„œ ì§ì ‘ í•´ë³´ê² ìŠµë‹ˆë‹¤. 



## Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë„êµ¬

### í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

- **ğŸ¤— Transformers**: ëª¨ë¸ ì•„í‚¤í…ì²˜(ìˆ˜ì²œ ê°œì˜ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ í¬í•¨), í† í¬ë‚˜ì´ì € ë° íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **ğŸ¤— Datasets**: ë°ì´í„°ì…‹ì„ ì‰½ê²Œ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬(Hub í†µí•© ë° íš¨ìœ¨ì ì¸ ë””ìŠ¤í¬ ê´€ë¦¬ í¬í•¨)
- **ğŸ¤— Hugging Face Hub (Python)**: ëª¨ë¸ ë° ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ/ì—…ë¡œë“œí•˜ê³  Hubì™€ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•œ ìœ í‹¸ë¦¬í‹°
- **ğŸ¤— Trainer API**: Transformers ë‚´ í¬í•¨ëœ, ë¡œê¹…/í‰ê°€ ë“±ì„ ì§€ì›í•˜ëŠ” ê³ ìˆ˜ì¤€ íŠ¸ë ˆì´ë„ˆ í´ë˜ìŠ¤
- **ğŸ¤— Accelerate**: ì½”ë“œ ë³€ê²½ ì—†ì´ ë¶„ì‚° í›ˆë ¨ ë° í˜¼í•© ì •ë°€ë„ë¥¼ ì§€ì›í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

### Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„¸

Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” Hugging Faceì˜ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜(BERT, GPT, LLaMA, Mistral ë“±)ë¥¼ êµ¬í˜„í•˜ê³ , ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ ì¶”ë¡ ì´ë‚˜ ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. NLP ì‘ì—…ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ì‘ì—…ì—ë„ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.

#### 1. AutoModelê³¼ AutoTokenizer

ì´ "auto" í´ë˜ìŠ¤ë“¤ì€ ëª¨ë¸ ì´ë¦„ì´ë‚˜ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´ë–¤ ì•„í‚¤í…ì²˜ë“  ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `AutoModel.from_pretrained("mistralai/Mistral-7B-v0.1")`ë¥¼ í˜¸ì¶œí•˜ë©´:

- Hubì—ì„œ ëª¨ë¸ êµ¬ì„±ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤(ëª¨ë¸ ìœ í˜• = Mistral).
- í•´ë‹¹ êµ¬ì„±ìœ¼ë¡œ ë‚´ë¶€ì ìœ¼ë¡œ MistralModel í´ë˜ìŠ¤ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•©ë‹ˆë‹¤.
- ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì— ë¡œë“œí•©ë‹ˆë‹¤.

ë‹¤ì–‘í•œ ì‘ì—…ì— ë§ëŠ” AutoModel ë³€í˜•ì´ ìˆìŠµë‹ˆë‹¤:
- `AutoModel`: ê¸°ë³¸ ëª¨ë¸ë§Œ ì œê³µ
- `AutoModelForCausalLM`: GPTë‚˜ LLaMA ê°™ì€ ì–¸ì–´ ëª¨ë¸ìš©

ë§ˆì°¬ê°€ì§€ë¡œ, `AutoTokenizer.from_pretrained(name)`ëŠ” ëª¨ë¸ êµ¬ì„±ì— ë”°ë¼ ì ì ˆí•œ í† í¬ë‚˜ì´ì €(LlamaTokenizer ë“±)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("qwen/qwen2.5-3b-instruct")
model = AutoModelForSequenceClassification.from_pretrained("qwen/qwen2.5-3b-instruct")

# í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì¶”ë¡ 
text = "Hugging FaceëŠ” ì •ë§ ë†€ë¼ìš´ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤!"
inputs = tokenizer(text, return_tensors='pt')
outputs = model(**inputs)
logits = outputs.logits
print(logits)  # í´ë˜ìŠ¤ì— ëŒ€í•œ ì›ì‹œ ì ìˆ˜
```

#### 2. í† í¬ë‚˜ì´ì €

`AutoTokenizer`(ë˜ëŠ” `LlamaTokenizer`ì™€ ê°™ì€ íŠ¹ì • í† í¬ë‚˜ì´ì €)ëŠ” ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤:
- í…ìŠ¤íŠ¸ë¥¼ í† í° IDë¡œ ë³€í™˜
- íŠ¹ìˆ˜ í† í° ì¶”ê°€([CLS], [SEP], [BOS], [EOS] ë“±)
- íŒ¨ë”©/ìë¥´ê¸° ì²˜ë¦¬
- í…ìŠ¤íŠ¸ë¡œ ë‹¤ì‹œ ë³€í™˜(ë””ì½”ë”©)

ê° ëª¨ë¸ ìœ í˜•ë§ˆë‹¤ ë‹¤ë¥¸ í† í¬ë‚˜ì´ì§• ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:
- GPT-2: ë°”ì´íŠ¸ í˜ì–´ ì¸ì½”ë”©(BPE)
- LLaMA/Mistral: SentencePiece ëª¨ë¸
- BERT: WordPiece

í† í¬ë‚˜ì´ì €ëŠ” Hubì˜ ëª¨ë¸ê³¼ í•¨ê»˜ ì €ì¥ë˜ë¯€ë¡œ, `from_pretrained`ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©ëœ ê²ƒê³¼ ë™ì¼í•œ ì–´íœ˜ì™€ ì „ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 3. íŒŒì´í”„ë¼ì¸

TransformersëŠ” ì¼ë°˜ì ì¸ ì‘ì—…ì„ ìœ„í•œ ê³ ìˆ˜ì¤€ íŒŒì´í”„ë¼ì¸ APIë„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ì€ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì ìˆ˜ì™€ í•¨ê»˜ "ê¸ì •" ë˜ëŠ” "ë¶€ì •"ì„ ì¶œë ¥í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ë‚´ë¶€ì ìœ¼ë¡œ í† í°í™”, ëª¨ë¸ ìˆœì „íŒŒ, ë””ì½”ë”©ì„ í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

```python
from transformers import pipeline

# ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ ìƒì„±
classifier = pipeline("sentiment-analysis")
result = classifier("Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì •ë§ ì¢‹ì•„ìš”!")[0]
print(result)
# {'label': 'POSITIVE', 'score': 0.9998}

# í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸
generator = pipeline("text-generation", model="meta-llama/Llama-2-7b-hf")
result = generator("ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ”", max_length=50, do_sample=True)
print(result[0]['generated_text'])
```



#### 4. í…ìŠ¤íŠ¸ ìƒì„± ì˜ˆì œ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2")
model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2", 
                                            torch_dtype=torch.float16,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ë°˜ì •ë°€ë„
                                            device_map="auto")  # ìë™ ì¥ì¹˜ ë§¤í•‘
model.eval()  # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •

# í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
prompt = "<s>[INST] ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ê°„ëµíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. [/INST]"
inputs = tokenizer(prompt, return_tensors='pt').to(model.device)

# í…ìŠ¤íŠ¸ ìƒì„±
outputs = model.generate(
    **inputs, 
    max_new_tokens=200,  # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
    do_sample=True,      # ìƒ˜í”Œë§ ì‚¬ìš©
    temperature=0.7,     # ì˜¨ë„ ì„¤ì • (ë‚®ì„ìˆ˜ë¡ ë” ê²°ì •ì )
    top_p=0.9            # ëˆ„ì  í™•ë¥ ì´ 0.9ê°€ ë  ë•Œê¹Œì§€ì˜ í† í°ë§Œ ê³ ë ¤
)

# ê²°ê³¼ ë””ì½”ë”© ë° ì¶œë ¥
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

ì´ ì˜ˆì œëŠ” Mistral-7B-Instruct ëª¨ë¸ì„ ë¡œë“œí•˜ê³  `.generate()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ íšŒê·€ í…ìŠ¤íŠ¸ ìƒì„±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì¶œë ¥ì€ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì¼ ê²ƒì…ë‹ˆë‹¤. `.generate` ë©”ì„œë“œì—ëŠ” ë””ì½”ë”©(ê·¸ë¦¬ë””, ë¹” ì„œì¹˜, ìƒ˜í”Œë§ ë“±)ì„ ìœ„í•œ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤.



### HuggingFace Hub ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„¸


Hugging Face Hub ë¼ì´ë¸ŒëŸ¬ë¦¬(`huggingface_hub`)ëŠ” Hugging Face ì €ì¥ì†Œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” low-level ë„êµ¬ì…ë‹ˆë‹¤. Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, ë…ë¦½ì ìœ¼ë¡œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° ëª¨ë“  ìœ í˜•ì˜ íŒŒì¼ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 1. ì¸ì¦

Hubì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì‚¬ìš©ì ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤:

```python
# ëª…ë ¹ì¤„ì—ì„œ ë¡œê·¸ì¸ (í† í°ì„ ë¡œì»¬ì— ì €ì¥)
!huggingface-cli login

# ë˜ëŠ” íŒŒì´ì¬ ì½”ë“œì—ì„œ ë¡œê·¸ì¸
from huggingface_hub import login
login(token="hf_...")  # ê°œì¸ ì•¡ì„¸ìŠ¤ í† í°
```

í† í°ì€ [Hugging Face ì„¤ì •](https://huggingface.co/settings/tokens)ì—ì„œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 2. íŒŒì¼ ë‹¤ìš´ë¡œë“œ

íŠ¹ì • ëª¨ë¸ì˜ íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œí•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤:

```python
from huggingface_hub import hf_hub_download

# íŠ¹ì • íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œ
config_file = hf_hub_download(
    repo_id="google/mt5-base", 
    filename="config.json"
)
```

#### 3. íŒŒì¼ ì—…ë¡œë“œ ë° ì €ì¥ì†Œ ê´€ë¦¬

```python
from huggingface_hub import HfApi, upload_file

# API ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
api = HfApi()

# ìƒˆ ì €ì¥ì†Œ ìƒì„±
api.create_repo(repo_id="username/my-new-model", private=True)

# ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ
upload_file(
    path_or_fileobj="./model.pt",  # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    path_in_repo="model.pt",       # ì €ì¥ì†Œ ë‚´ ê²½ë¡œ
    repo_id="username/my-new-model"
)

# í´ë” ì „ì²´ ì—…ë¡œë“œ
api.upload_folder(
    folder_path="./model_files",
    repo_id="username/my-new-model",
    repo_type="model"
)
```

#### 4. Gitê³¼ Repository í´ë˜ìŠ¤ í™œìš©

Hub ì €ì¥ì†ŒëŠ” Git ì €ì¥ì†Œì´ë¯€ë¡œ Git ëª…ë ¹ì–´ë¡œ ì§ì ‘ ì‘ì—…í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:

```python
from huggingface_hub import Repository

# ì €ì¥ì†Œ ë¡œì»¬ì— í´ë¡ 
repo = Repository(
    local_dir="./my-model-dir", 
    clone_from="username/my-model"
)

# íŒŒì¼ ì¶”ê°€/ìˆ˜ì • í›„ ì»¤ë°‹ ë° í‘¸ì‹œ
with open("./my-model-dir/README.md", "w") as f:
    f.write("# ë‚´ ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…\n\nì´ ëª¨ë¸ì€...")

repo.git_add("README.md")
repo.git_commit("README ì—…ë°ì´íŠ¸")
repo.git_push()
```

#### 5. ëª¨ë¸ ì¹´ë“œ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬

```python
from huggingface_hub import ModelCard, CardData

# ëª¨ë¸ ì¹´ë“œ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
card_data = CardData(
    language="ko",
    license="mit",
    tags=["text-classification", "korean"],
    datasets=["klue"],
    metrics=[{"name": "accuracy", "value": 0.92}]
)

card = ModelCard.from_template(
    card_data=card_data,
    template_path="modelcard_template.md"  # ì˜µì…˜: ì»¤ìŠ¤í…€ í…œí”Œë¦¿
)

card.push_to_hub("username/my-model")
```

#### 6. Trainerì™€ì˜ í†µí•©

Transformers `Trainer`ë¥¼ ì‚¬ìš©í•œë‹¤ë©´, í›ˆë ¨ì´ ëë‚œ í›„ í•œ ì¤„ë¡œ ëª¨ë¸ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥ì†Œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# í›ˆë ¨ í›„ ì €ì¥ì†Œì— ì—…ë¡œë“œ
trainer.push_to_hub()
```

ì´ ëª…ë ¹ì€ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥í•˜ê³ , í•™ìŠµ ë¡œê·¸ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ ëª¨ë¸ ì¹´ë“œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ì—…ë¡œë“œí•©ë‹ˆë‹¤.



### Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„¸

ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë°ì´í„°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¡œë“œ, ì²˜ë¦¬, ê³µìœ í•˜ê¸° ìœ„í•œ ë„êµ¬ì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ë©”ëª¨ë¦¬ì— ë§ê²Œ ìŠ¤íŠ¸ë¦¬ë°í•˜ê±°ë‚˜ ë©”ëª¨ë¦¬ ë§¤í•‘í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, Hugging Face Hubì™€ í†µí•©ë˜ì–´ ìˆ˜ë§ì€ ê³µê°œ ë°ì´í„°ì…‹ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 1. ë°ì´í„°ì…‹ ë¡œë“œ

`load_dataset` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ì…‹ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from datasets import load_dataset

# Hubì—ì„œ ê³µê°œ ë°ì´í„°ì…‹ ë¡œë“œ
squad_dataset = load_dataset("squad")  # SQuAD ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹

# íŠ¹ì • ì‚¬ìš©ìì˜ ë°ì´í„°ì…‹ ë¡œë“œ
custom_dataset = load_dataset("username/my_dataset")

# ë¡œì»¬ íŒŒì¼ì—ì„œ ë¡œë“œ
csv_dataset = load_dataset("csv", data_files="my_data.csv")
json_dataset = load_dataset("json", data_files="data.jsonl")

# ì—¬ëŸ¬ íŒŒì¼ ë˜ëŠ” ë¶„í•  ì§€ì •
multi_dataset = load_dataset("csv", data_files={
    "train": "train_data.csv",
    "validation": "val_data.csv"
})
```

DatasetsëŠ” CSV, JSON, Parquet, Text, Image ë“± ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤. ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì˜ ê²½ìš°, ì»¤ìŠ¤í…€ ë¡œë” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ê±°ë‚˜ íŒŒì´ì¬ì—ì„œ ì§ì ‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ Dataset ê°ì²´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 2. Dataset ê°ì²´ êµ¬ì¡°

ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ë©´ ì¼ë°˜ì ìœ¼ë¡œ `Dataset` ê°ì²´(ë‹¨ì¼ ë¶„í• ) ë˜ëŠ” `DatasetDict`(ì—¬ëŸ¬ ë¶„í• )ë¥¼ ì–»ê²Œ ë©ë‹ˆë‹¤:

```python
# Dataset êµ¬ì¡° í™•ì¸
dataset = load_dataset("glue", "sst2")
print(type(dataset))  # <class 'datasets.dataset_dict.DatasetDict'>
print(dataset.keys())  # dict_keys(['train', 'validation', 'test'])

# íŠ¹ì • ë¶„í•  ì ‘ê·¼
train_dataset = dataset["train"]
print(len(train_dataset))  # ì˜ˆ: 67349 (í•­ëª© ìˆ˜)
print(train_dataset.features)  # ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸

# ê°œë³„ í•­ëª© ì ‘ê·¼
print(train_dataset[0])  # ì²« ë²ˆì§¸ í•­ëª© (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
```


#### 3. ë°ì´í„°ì…‹ ì²˜ë¦¬

Dataset ê°ì²´ëŠ” ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ë©”ì†Œë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤:

##### map í•¨ìˆ˜ë¡œ ë°ì´í„° ë³€í™˜

```python
from transformers import AutoTokenizer

# í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")

# í…ìŠ¤íŠ¸ í† í°í™” í•¨ìˆ˜
def tokenize_function(examples):
    return tokenizer(
        examples["sentence"],
        padding="max_length",
        truncation=True,
        max_length=128
    )

# ëª¨ë“  ì˜ˆì œì— í•¨ìˆ˜ ì ìš© (ë³‘ë ¬ ì²˜ë¦¬)
tokenized_dataset = dataset["train"].map(
    tokenize_function,
    batched=True,  # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
    num_proc=4     # ë³‘ë ¬ ì²˜ë¦¬ (CPU ì½”ì–´ ìˆ˜ì— ë”°ë¼ ì¡°ì •)
)
```

map í•¨ìˆ˜ëŠ” ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ìºì‹±í•˜ë¯€ë¡œ, ë™ì¼í•œ ì²˜ë¦¬ë¥¼ ë°˜ë³µí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.

##### í•„í„°ë§ê³¼ ì •ë ¬

```python
# íŠ¹ì • ì¡°ê±´ìœ¼ë¡œ í•„í„°ë§
short_dataset = dataset["train"].filter(lambda x: len(x["sentence"]) < 100)

# íŠ¹ì • ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬
sorted_dataset = dataset["train"].sort("label")

# ë°ì´í„°ì…‹ ì„ê¸°
shuffled_dataset = dataset["train"].shuffle(seed=42)

# ë¶„í• 
train_test = dataset["train"].train_test_split(test_size=0.2)
# ê²°ê³¼: DatasetDict({'train': Dataset(...), 'test': Dataset(...)})
```

#### 4. ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë°

ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•  ë•Œ RAM ì‚¬ìš©ëŸ‰ì„ ê´€ë¦¬í•˜ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤:

```python
# ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ë°ì´í„°ì…‹ ë¡œë“œ (ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•ŠìŒ)
streamed_dataset = load_dataset("c4", "ko", split="train", streaming=True)

# ì´í„°ë ˆì´í„°ë¡œ ì‚¬ìš©
for example in streamed_dataset:
    # í•œ ë²ˆì— í•˜ë‚˜ì˜ ì˜ˆì œë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ
    process_example(example)
    
# ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì…‹ì˜ ì¼ë¶€ë§Œ í™•ì¸
for i, example in enumerate(streamed_dataset):
    if i >= 5:  # ì²˜ìŒ 5ê°œë§Œ í™•ì¸
        break
    print(example)
```

ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì…‹ì—ë„ `.map()`, `.filter()` ë“±ì„ ì ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì´ ê²½ìš° ë³€í™˜ì´ ì§€ì—° ì²˜ë¦¬(lazy processing)ë©ë‹ˆë‹¤.

#### 5. Transformersì™€ í†µí•©

DatasetsëŠ” Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì›í™œí•˜ê²Œ í†µí•©ë©ë‹ˆë‹¤:

```python
# PyTorch í…ì„œ í˜•ì‹ìœ¼ë¡œ ì„¤ì •
tokenized_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "label"])

# Trainerì— ì§ì ‘ ì „ë‹¬
from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("klue/bert-base")
training_args = TrainingArguments(output_dir="./results", num_train_epochs=3)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"]
)

trainer.train()
```

#### 6. Hubì™€ ë°ì´í„°ì…‹ ê³µìœ 

ì²˜ë¦¬í•œ ë°ì´í„°ì…‹ì„ Hugging Face Hubì— ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ë°ì´í„°ì…‹ì„ Hubì— ì—…ë¡œë“œ
processed_dataset.push_to_hub("username/my_processed_dataset")

# ë©”íƒ€ë°ì´í„° ë° ì¹´ë“œ ì •ë³´ í¬í•¨
processed_dataset.push_to_hub(
    "username/my_processed_dataset",
    repository_url="https://huggingface.co/datasets/username/my_processed_dataset",
    commit_message="Add processed Korean sentiment dataset"
)
```

ë°ì´í„°ì…‹ì„ ê³µìœ í•˜ë©´ ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì´ `load_dataset("username/my_processed_dataset")`ìœ¼ë¡œ ì‰½ê²Œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 8. ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì‘ì—… íŒ

ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì‘ì—… ì‹œ ì¶”ì²œë˜ëŠ” ë°©ë²•ë“¤:

- ë©”ëª¨ë¦¬ ë§µí•‘: DatasetsëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë§µí•‘ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ì„ RAMì— ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì»¬ëŸ¼ ì„ íƒ: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ (`dataset.select_columns(["text", "label"])`)
- ë°°ì¹˜ ì²˜ë¦¬: `.map(batch_size=1000)`ìœ¼ë¡œ ëŒ€ê·œëª¨ ë³€í™˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
- ìºì‹± í™œìš©: ê¸°ë³¸ì ìœ¼ë¡œ `.map()` ê²°ê³¼ëŠ” ìºì‹œë˜ì§€ë§Œ, í•„ìš”í•˜ë©´ `load_from_cache_file=False`ë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥
- ë¶„ì‚° ì²˜ë¦¬: `num_proc` ì¸ìë¡œ ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš©

Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ ì„¤ê³„ë˜ì–´, ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì„ í¬ê²Œ ê°„ì†Œí™”í•©ë‹ˆë‹¤.



### Hugging Face Spaces (Gradio / Streamlit ì•± í˜¸ìŠ¤íŒ…)

SpacesëŠ” Hugging Faceì˜ ë¼ì´ë¸Œ ë¨¸ì‹ ëŸ¬ë‹ ë°ëª¨ ë° ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í˜¸ìŠ¤íŒ…í•˜ê¸° ìœ„í•œ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. SpaceëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ì›¹ ì•±(ì£¼ë¡œ Gradio ë˜ëŠ” Streamlit ì‚¬ìš©)ì„ ì‹¤í–‰í•˜ê³  ì§€ì†ì ì¸ URLì„ í†µí•´ ë‹¤ë¥¸ ì‚¬ìš©ìì™€ ê³µìœ í•  ìˆ˜ ìˆëŠ” ìƒŒë“œë°•ìŠ¤ í™˜ê²½ì…ë‹ˆë‹¤.

#### 1. Space ìƒì„± ë° ê³µìœ 

- SpaceëŠ” Git ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤
- Hubì—ì„œ ìƒˆ Spaceë¥¼ ë§Œë“¤ê³  ì´ë¦„ ì„ íƒ, ê³µê°œ/ë¹„ê³µê°œ ì„¤ì •, SDK ìœ í˜•ì„ ì„ íƒí•©ë‹ˆë‹¤
- ì½”ë“œë¥¼ í‘¸ì‹œí•˜ë©´ Spaceê°€ ìë™ìœ¼ë¡œ ë¹Œë“œë˜ê³  ì‹¤í–‰ë©ë‹ˆë‹¤

#### 2. ê°œë°œ ë„êµ¬
- **Gradio**: ëª¨ë¸ìš© ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤
  - í•¨ìˆ˜(ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì¶œë ¥ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ˆì¸¡ í•¨ìˆ˜ ë“±)ë¥¼ ì •ì˜í•˜ë©´ Gradioê°€ í…ìŠ¤íŠ¸ ë°•ìŠ¤, ë²„íŠ¼ ë“±ê³¼ í•¨ê»˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
- **Streamlit**: Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‘ì€ ì›¹ ì•±ì„ ì‘ì„±í•˜ëŠ” ê²ƒê³¼ ë” ìœ ì‚¬í•©ë‹ˆë‹¤
  - ê·¸ë˜í”„, ìœ„ì ¯ ë“±ì—ë„ ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤, ìš”ì¦˜ ê°€ì¥ ê°„ë‹¨í•˜ê²Œ íŒŒì´ì¬ìœ¼ë¡œ ì›¹ ì•±ì„ ë§Œë“œëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. 

#### 3. í•˜ë“œì›¨ì–´ ë° ìŠ¤ì¼€ì¼ë§
- **ê¸°ë³¸ ì‚¬ì–‘**: ë¬´ë£Œ CPU ì „ìš© ì»¨í…Œì´ë„ˆ(16GB RAM)
  - ì‘ì€ ëª¨ë¸ì´ë‚˜ ì¶”ë¡  APIë¥¼ í˜¸ì¶œí•˜ëŠ” ë°ëª¨ì— ì í•©
- **GPU ì—…ê·¸ë ˆì´ë“œ (ìœ ë£Œ)**: ëŒ€í˜• ëª¨ë¸ í˜¸ìŠ¤íŒ… ì‹œ í•„ìš”
  - T4, A10G, A100 ë“± ë‹¤ì–‘í•œ í‹°ì–´ ì œê³µ
  - ì‹œê°„ë‹¹ ê³¼ê¸ˆ ë°©ì‹

#### 4. Spaces í™œìš© ì‚¬ë¡€
- OpenLLM Learderboard











